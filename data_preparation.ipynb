{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claim files for merging\n",
    "claims1 = pd.read_csv('../../DE1_0_2008_to_2010_Carrier_Claims_Sample_2A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims2 = pd.read_csv('../../DE1_0_2008_to_2010_Carrier_Claims_Sample_2B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merging two claims files\n",
    "claims = pd.concat([claims1, claims2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtain inpatient claims\n",
    "inpatient = pd.read_csv('../../DE1_0_2008_to_2010_Inpatient_Claims_Sample_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain outpatient claims data\n",
    "outpatient = pd.read_csv('../../DE1_0_2008_to_2010_Outpatient_Claims_Sample_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain prescription drug data\n",
    "pde = pd.read_csv('../../DE1_0_2008_to_2010_Prescription_Drug_Events_Sample_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Beneficiary data files for merging\n",
    "ben8 = pd.read_csv('../../DE1_0_2008_Beneficiary_Summary_File_Sample_2.csv')\n",
    "ben9 = pd.read_csv('../../DE1_0_2009_Beneficiary_Summary_File_Sample_2.csv')\n",
    "ben10 = pd.read_csv('../../DE1_0_2010_Beneficiary_Summary_File_Sample_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ben_all = pd.concat([ben8, ben9, ben10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select a random sample of patients for further analysis if sample=True\n",
    "\n",
    "sample = False\n",
    "\n",
    "if sample is True:\n",
    "    sample_patient_ids = ben10.DESYNPUF_ID.sample(frac = 0.5)\n",
    "else:\n",
    "    sample_patient_ids = ben10.DESYNPUF_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write beneficiary features of interest for corresponding patients into a single dataframe for preprocessing\n",
    "\n",
    "working_df = pd.DataFrame(index = ben10.index)\n",
    "\n",
    "beneficiary_features = ['DESYNPUF_ID','BENE_SEX_IDENT_CD', 'BENE_RACE_CD', 'BENE_BIRTH_DT', 'SP_STATE_CODE', \n",
    "                        'BENE_COUNTY_CD','SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD', 'SP_DIABETES', 'SP_DEPRESSN', \n",
    "                        'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA', 'MEDREIMB_OP', 'BENRES_OP', \n",
    "                        'PPPYMT_OP', 'BENE_DEATH_DT']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select beneficiary data corresponding to the sample size\n",
    "working_df = ben10[ben10.DESYNPUF_ID.isin(sample_patient_ids)]\n",
    "\n",
    "\n",
    "#Drop features that are not of interest\n",
    "for col in working_df:\n",
    "    print(col)\n",
    "    if col not in beneficiary_features:\n",
    "        working_df.drop(col, axis = 1, inplace = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop rows and columns where all elements are NULL\n",
    "working_df = working_df.dropna(axis=1, how='all')\n",
    "working_df = working_df.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a variable indicating if a patient has passed away\n",
    "working_df['DEATH'] = working_df.BENE_DEATH_DT.apply(lambda x: 1 if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add hospitalization date to the working dataframe\n",
    "working_df = pd.merge(working_df, inpatient[['DESYNPUF_ID','CLM_ADMSN_DT']], how='left', on='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_date - start date of forecasting patients hospitalization \n",
    "target_date = 20100101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create target variable Y showing 1 if patient has been hospitalized in the target dataframe\n",
    "max_ip_date = working_df.CLM_ADMSN_DT.groupby(working_df.DESYNPUF_ID).max()\n",
    "inp_dates = pd.DataFrame(list(max_ip_date.items()), columns = ['DESYNPUF_ID', 'CLM_ADMSN_DT'])\n",
    "inp_dates['Y'] = inp_dates.CLM_ADMSN_DT.apply(lambda x: 1 if x >= target_date else 0)\n",
    "working_df = pd.merge(working_df, inp_dates[['DESYNPUF_ID','Y']], how='left', on='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If hospitalized, first admission date in the target dataframe\n",
    "dates = {}\n",
    "sub_df = working_df[working_df.Y==1]\n",
    "\n",
    "for patient in sub_df.DESYNPUF_ID.unique():\n",
    "    hosp_dates = working_df[working_df.DESYNPUF_ID==patient].CLM_ADMSN_DT\n",
    "    min_date_2010 = min(hosp_dates[hosp_dates>=20100101])\n",
    "    dates[patient] = min_date_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding first admission date to the dataframe\n",
    "df_dates = pd.DataFrame(list(dates.items()), columns = ['DESYNPUF_ID', 'fst_admsn_dt'])\n",
    "working_df = pd.merge(working_df, df_dates[['DESYNPUF_ID','fst_admsn_dt']], how='left', on='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import dateutil\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "\n",
    "def clean_df(df):\n",
    "    \n",
    "    '''Takes as input a DataFrame, creates a dummy variable for the death date (0 if still alive, 1 if not).\n",
    "    Calculates the column TRUE_AGE, according to the death date if the dummy variable indicating death is 1, \n",
    "    or according to today's date if the dummy variable is 0. Recodes the column BENE_SEX_IDENT_CD (Sex) as \n",
    "    1: Female, 0: Male. '''\n",
    "    \n",
    "    days_a_year = 365.24\n",
    "    \n",
    "    ## Filling the missing values with 0, as explained above\n",
    "    df['BENE_DEATH_DT'] = df['BENE_DEATH_DT'].fillna(0)\n",
    "    \n",
    "    ## Creating the column DEATH_DUMMY, 1 if the patient is dead, 0 otherwise\n",
    "    df['DEATH_DUMMY'] = [int(int(df['BENE_DEATH_DT'][k])>0) for k in range(len(df['BENE_DEATH_DT']))]\n",
    "    df['BENE_BIRTH_DT'] = [str(j) for j in df['BENE_BIRTH_DT']]\n",
    "    \n",
    "    df['BENE_DEATH_DT'] = [str(int(\"%2.f\" % float(j))) for j in df['BENE_DEATH_DT']]\n",
    "    \n",
    "    bday_date = [dateutil.parser.parse(date) for date in df['BENE_BIRTH_DT']]\n",
    "    \n",
    "    death_date = []\n",
    "    for d in range(len(df)):\n",
    "        if df['DEATH_DUMMY'][d] == 0:\n",
    "            death_date.append(dateutil.parser.parse(str(20100101)))\n",
    "        elif df['DEATH_DUMMY'][d] == 1:\n",
    "            death_date.append(dateutil.parser.parse(df['BENE_DEATH_DT'][d]))\n",
    "    \n",
    "    df['TRUE_AGE'] = [((death_date[j] - bday_date[j])/days_a_year).days for j in range(len(df['BENE_BIRTH_DT']))]\n",
    "    \n",
    "        ## Sex recoded to (0:Male, 1:Female) \n",
    "    df['BENE_SEX_IDENT_CD'] = [int(df['BENE_SEX_IDENT_CD'][i] == 2) for i in range(len(df['BENE_SEX_IDENT_CD']))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df(working_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df['first_ad_date']=clean_df.fst_admsn_dt.astype(str).apply(lambda x: pd.to_datetime(x, format='%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "def add_months(sourcedate, months):\n",
    "    mmonth = sourcedate.month - 1 + months\n",
    "    yyear = int(sourcedate.year + mmonth / 12)\n",
    "    mmonth = mmonth % 12 + 1\n",
    "    dday = min(sourcedate.day,calendar.monthrange(yyear,mmonth)[1])\n",
    "    return datetime.date(yyear,mmonth,dday)\n",
    "\n",
    "\n",
    "clean_df.first_ad_date.fillna(datetime.date(3000,1,1), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df.Y==1].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "clean_df.first_ad_date.fillna(datetime.date(3000,1,1), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['end_train_dt']=clean_df.first_ad_date.apply(lambda x: add_months(x,-6))\n",
    "clean_df.end_train_dt.replace(datetime.date(2999,7,1),datetime.date(2010,6,30),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.CLM_ADMSN_DT.fillna(datetime.date(3000,1,1), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['start_train_dt']=datetime.date(2008,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_month(d1, d2):\n",
    "    return(d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "import math\n",
    "\n",
    "date1 = datetime.date(2009, 7, 13)\n",
    "date2 = datetime.date(2008, 1, 1)\n",
    "date2\n",
    "\n",
    "def month_difference(date1, date2):\n",
    "    \n",
    "    '''Takes as input two dates, takes their timedelta, if it is exactly x.5 months returns x.5 months,\n",
    "    if it is between x and x.5 months returns x months, and if it is between x.5 months and ceiling(x),\n",
    "    returns ceiling(x)'''\n",
    "    \n",
    "    date_diff_days = (date1 - date2).days ## timedelta.days, it doesn't have months or years methods unfortunately\n",
    "    date_diff_months = (date_diff_days/30.4)\n",
    "    \n",
    "    if math.ceil(date_diff_months) - date_diff_months > 0.5:\n",
    "        return math.trunc(date_diff_months)\n",
    "    elif math.ceil(date_diff_months) - date_diff_months <= 0.5:\n",
    "        return math.ceil(date_diff_months)\n",
    "    else:\n",
    "        return (math.trunc(date_diff_months) + 0.5) \n",
    "        \n",
    "\n",
    "month_difference(date1, date2)\n",
    "\n",
    "clean_df['member_months'] = [month_difference(clean_df['end_train_dt'][i], clean_df['start_train_dt'][i]) for i in range(len(clean_df))]\n",
    "\n",
    "clean_df[clean_df.Y==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous inpatient hospitalization date (last date in the training period)\n",
    "\n",
    "print(clean_df.shape)\n",
    "print(inpatient.shape)\n",
    "\n",
    "N = 100000000\n",
    "clean_sub = clean_df.iloc[0:min(clean_df.shape[0],N),:]\n",
    "inpat_sub = inpatient.iloc[0:min(inpatient.shape[0],N),:]\n",
    "\n",
    "prev_hosp_dt = {}\n",
    "\n",
    "print('figuring end dates')\n",
    "dates = clean_sub.end_train_dt.groupby(clean_df.DESYNPUF_ID).max()\n",
    "print('DONE figuring end dates')\n",
    "\n",
    "def process_patient_rows(rows):\n",
    "    global dates, prev_hosp_dt\n",
    "    if len(prev_hosp_dt) % 1000 == 0:\n",
    "        print(str(len(prev_hosp_dt)))\n",
    "    pat_id = rows.DESYNPUF_ID.iloc[0]\n",
    "    if pat_id not in dates:\n",
    "        return\n",
    "    last_training_date = dates[pat_id]\n",
    "\n",
    "    training_selection = rows.CLM_ADMSN_DT.apply(\n",
    "        lambda x: (dateutil.parser.parse(str(x))).date() <= last_training_date)\n",
    "    last_hosp_date = rows.CLM_ADMSN_DT[training_selection].max()\n",
    "    if not np.isnan(last_hosp_date):\n",
    "        prev_hosp_dt[pat_id] = last_hosp_date\n",
    "    \n",
    "inpat_sub.groupby(inpat_sub.DESYNPUF_ID).apply(lambda rows: process_patient_rows(rows))\n",
    "\"\"\"\n",
    "for patient in inpat_sub.DESYNPUF_ID.unique():\n",
    "    \n",
    "    patient_rows = inpat_sub[inpat_sub.DESYNPUF_ID == patient]\n",
    "\"\"\"\n",
    "print(len(prev_hosp_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to date type and add to the data frame\n",
    "prev_hosp = pd.DataFrame(list(prev_hosp_dt.items()), columns = ['DESYNPUF_ID', 'prev_hosp'])\n",
    "prev_hosp['prev_hosp_dt']=prev_hosp.prev_hosp.astype(str).apply(lambda x: pd.to_datetime(x, format='%Y%m%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add hospitalization date to the working dataframe\n",
    "clean_df = pd.merge(clean_df, prev_hosp[['DESYNPUF_ID','prev_hosp_dt']], how='left', on='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique IP dates in training period\n",
    "unique_ip = inpatient.CLM_ADMSN_DT.groupby(inpatient.DESYNPUF_ID).nunique()\n",
    "unique_ip_dt = pd.DataFrame({'DESYNPUF_ID':unique_ip.index, 'unique_ip_dt':unique_ip.values})\n",
    "clean_df = pd.merge(clean_df, unique_ip_dt[['DESYNPUF_ID','unique_ip_dt']], how='left', on='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dollar spend on inpatient claims in training period\n",
    "inpatient['CLM_THRU_DT'].fillna(30000101.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inpatient['CLM_THRU_DT'] = [str(int(x)) for x in inpatient['CLM_THRU_DT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatient['CLM_THRU_DT'] = [dateutil.parser.parse(str(date)).date() for date in inpatient['CLM_THRU_DT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add inpatient payment amounts in the training set\n",
    "\n",
    "inpatient = pd.merge(inpatient, clean_df[['DESYNPUF_ID','end_train_dt']], how='left', on='DESYNPUF_ID')\n",
    "\n",
    "inpatient['count_clm'] = inpatient.CLM_THRU_DT<inpatient.end_train_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add inpatient payment amounts p.2\n",
    "agg = pd.pivot_table(inpatient,values \n",
    "               =['CLM_PMT_AMT'],index=['count_clm'],columns=['DESYNPUF_ID'],aggfunc=np.sum).transpose()\n",
    "\n",
    "comp = pd.DataFrame(agg.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add inpatient payment amounts p.3\n",
    "\n",
    "clean_df = pd.merge(clean_df, comp[['DESYNPUF_ID','True']],how='left',on='DESYNPUF_ID')\n",
    "\n",
    "clean_df.rename(index=str, columns={\"True\": \"IP_PMT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.rename(index=str, columns={\"True\": \"IP_PMT\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create variable indicating number of days from previous hospitalization\n",
    "# last_hosp_date = working_df.DESYNPUF_ID.apply(lambda x: max(working_df.CLM_ADMSN_DT[working_df.DESYNPUF_ID==x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = clean_df.drop_duplicates('DESYNPUF_ID')\n",
    "final.DESYNPUF_ID.duplicated().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write pre-selected data into a csv for cleaning and feature selection\n",
    "final.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
